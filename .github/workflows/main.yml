from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
import pandas as pd
import time

def scrape_teema():
    # è¨­å®š Headless Chrome (ç„¡é ­æ¨¡å¼ï¼Œé©åˆ GitHub ç’°å¢ƒ)
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    all_companies = []

    try:
        url = "https://b2b.teema.org.tw/CompanyList.aspx"
        driver.get(url)
        wait = WebDriverWait(driver, 20)

        # æŠ“å– 1 åˆ° 4 é  (å°æ‡‰ ctl02-ctl05)
        for p in range(1, 5):
            print(f"ç›®å‰æ­£åœ¨è™•ç†ç¬¬ {p} é ...")
            time.sleep(3) # ç­‰å¾…è³‡æ–™è¼‰å…¥
            
            # æŠ“å–ç•¶å‰é é¢çš„å…¬å¸åç¨±
            links = driver.find_elements(By.CSS_SELECTOR, 'a[id*="hlCompanyName"]')
            for l in links:
                name = l.text.strip()
                if name: all_companies.append({"å…¬å¸åç¨±": name})
            
            print(f"ç¬¬ {p} é å®Œæˆï¼Œç›®å‰ç´¯è¨ˆ {len(all_companies)} ç­†")

            # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€é ï¼Œå°±é»æ“Šä¸‹ä¸€é 
            if p < 4:
                btn_id = f"ctl00_ContentPlaceHolder1_Repeater1_ctl0{p+1}_lnkPage"
                print(f"å˜—è©¦é»æ“ŠæŒ‰éˆ• ID: {btn_id}")
                next_btn = wait.until(EC.element_to_be_clickable((By.ID, btn_id)))
                next_btn.click()
                time.sleep(2)

    except Exception as e:
        print(f"çˆ¬å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        driver.quit()

    if all_companies:
        df = pd.DataFrame(all_companies).drop_duplicates()
        df.to_csv("teema_companies.csv", index=False, encoding="utf-8-sig")
        print(f"ğŸ‰ æˆåŠŸï¼ç¸½å…±æŠ“å– {len(df)} ç­†å…¬å¸è³‡æ–™ã€‚")

if __name__ == "__main__":
    scrape_teema()
