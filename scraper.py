import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
import pandas as pd
import time

def scrape_teema():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    
    # é é˜²æ€§å»ºç«‹ç©ºæª”
    pd.DataFrame(columns=["å…¬å¸åç¨±"]).to_csv("teema_companies.csv", index=False, encoding="utf-8-sig")

    try:
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        url = "https://b2b.teema.org.tw/CompanyList.aspx"
        driver.get(url)
        wait = WebDriverWait(driver, 30)

        all_companies = []
        page_num = 1

        while True:
            print(f"ğŸš€ ç›®å‰æ­£åœ¨è™•ç†ç¬¬ {page_num} é ...")
            
            # ç­‰å¾…è³‡æ–™è¼‰å…¥
            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a[id*="CompanyName"]')))
            except:
                print("ç­‰å¾…è¶…æ™‚ï¼Œå¯èƒ½å·²åˆ°æœ«é æˆ–ç¶²è·¯ç•°å¸¸ã€‚")
                break
                
            time.sleep(3) # ç·©è¡æ™‚é–“
            
            # æŠ“å–ç•¶å‰é é¢è³‡æ–™
            links = driver.find_elements(By.CSS_SELECTOR, 'a[id*="CompanyName"]')
            for l in links:
                name = l.text.strip()
                if name:
                    all_companies.append({"å…¬å¸åç¨±": name})
            
            print(f"âœ… ç¬¬ {page_num} é å®Œæˆï¼Œç›®å‰ç´¯è¨ˆ {len(all_companies)} ç­†è³‡æ–™")

            # å„²å­˜æš«å­˜æª”ï¼Œé é˜²ç¨‹å¼ä¸­æ–·
            pd.DataFrame(all_companies).drop_duplicates().to_csv("teema_companies.csv", index=False, encoding="utf-8-sig")

            # å°‹æ‰¾ã€Œä¸‹ä¸€é ã€æŒ‰éˆ•
            # ASP.NET çš„ä¸‹ä¸€é æŒ‰éˆ•é€šå¸¸æ˜¯ä¸€å€‹åŒ…å« ">" æˆ– "Next" çš„ LinkButton
            try:
                # å°‹æ‰¾æ–‡å­—å…§å®¹åŒ…å« ">" çš„æŒ‰éˆ•ï¼Œé€™é€šå¸¸æ˜¯ä¸‹ä¸€é çš„ç¬¦è™Ÿ
                next_btns = driver.find_elements(By.XPATH, "//a[contains(text(), '>')]")
                if next_btns:
                    next_btn = next_btns[0]
                    # æ»¾å‹•åˆ°è©²æŒ‰éˆ•ä½ç½®
                    driver.execute_script("arguments[0].scrollIntoView();", next_btn)
                    time.sleep(1)
                    driver.execute_script("arguments[0].click();", next_btn)
                    page_num += 1
                    time.sleep(2)
                else:
                    print("ğŸ æ‰¾ä¸åˆ°ä¸‹ä¸€é æŒ‰éˆ•ï¼ŒæŠ“å–çµæŸã€‚")
                    break
            except Exception as e:
                print(f"åœæ­¢è·³é çš„åŸå› : {e}")
                break

        print(f"ğŸ‰ ä»»å‹™å¤§æˆåŠŸï¼ç¸½å…±æŠ“å– {len(all_companies)} ç­†å…¬å¸åå–®ã€‚")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        if 'driver' in locals():
            driver.quit()

if __name__ == "__main__":
    scrape_teema()
